{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a19fb02",
   "metadata": {},
   "source": [
    "# ID Minter Demo\n",
    "\n",
    "This notebook demonstrates the ID Minter functionality for stable identifiers during source system migrations.\n",
    "\n",
    "## What this covers\n",
    "\n",
    "1. **Batch lookup** - Efficient lookup of multiple source identifiers\n",
    "2. **Batch minting** - Combined lookup and mint in a single transaction\n",
    "3. **Predecessor inheritance** - How new records inherit canonical IDs from old systems\n",
    "4. **New record minting** - Minting brand new records from the pre-generated pool\n",
    "5. **Race condition protection** - Demonstrating concurrent access safety\n",
    "6. **Alias discovery** - Finding which source identifiers share a canonical ID\n",
    "\n",
    "For the schema migration process, see [schema_migration.ipynb](schema_migration.ipynb).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Docker installed\n",
    "- [uv](https://docs.astral.sh/uv/) installed\n",
    "\n",
    "## Setup\n",
    "\n",
    "```bash\n",
    "cd /Users/kennyr/workspace/docs/rfcs/XXX-stable_identifiers\n",
    "\n",
    "# Install dependencies and create virtual environment\n",
    "uv sync\n",
    "\n",
    "# Start the MySQL container\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "Then select the `.venv` Python interpreter for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fc93ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to MySQL successfully\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from id_minter import generate_canonical_id\n",
    "\n",
    "# Database connection settings\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 3306,\n",
    "    'user': 'root',\n",
    "    'password': 'rootpassword',\n",
    "    'database': 'id_minter'\n",
    "}\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"Get a database connection.\"\"\"\n",
    "    return pymysql.connect(**DB_CONFIG, cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "def execute_query(query: str, params: tuple = None, fetch: bool = False):\n",
    "    \"\"\"Execute a query and optionally fetch results.\"\"\"\n",
    "    conn = get_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query, params)\n",
    "            if fetch:\n",
    "                return cursor.fetchall()\n",
    "            conn.commit()\n",
    "            return cursor.rowcount\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    conn = get_connection()\n",
    "    conn.close()\n",
    "    print(\"✓ Connected to MySQL successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Connection failed: {e}\")\n",
    "    print(\"\\nMake sure docker-compose is running:\")\n",
    "    print(\"  cd /Users/kennyr/workspace/docs/rfcs/XXX-stable_identifiers\")\n",
    "    print(\"  docker-compose up -d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f45de",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "\n",
    "Create the schema and load sample data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34a58a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Schema created\n",
      "✓ Loaded 10000 sample records\n",
      "✓ Pre-generated 200 free IDs\n",
      "\n",
      "Canonical ID pool status:\n",
      "  free         200 IDs\n",
      "  assigned   10000 IDs\n"
     ]
    }
   ],
   "source": [
    "# Reset and create schema\n",
    "execute_query(\"DROP TABLE IF EXISTS identifiers\")\n",
    "execute_query(\"DROP TABLE IF EXISTS identifiers_old\")\n",
    "execute_query(\"DROP TABLE IF EXISTS canonical_ids\")\n",
    "\n",
    "# Create canonical_ids table\n",
    "execute_query(\"\"\"\n",
    "CREATE TABLE canonical_ids (\n",
    "    CanonicalId VARCHAR(8) NOT NULL PRIMARY KEY,\n",
    "    Status ENUM('free', 'assigned') NOT NULL DEFAULT 'free',\n",
    "    CreatedAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    INDEX idx_free (Status, CanonicalId)\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=latin1\n",
    "\"\"\")\n",
    "\n",
    "# Create identifiers table\n",
    "execute_query(\"\"\"\n",
    "CREATE TABLE identifiers (\n",
    "    OntologyType VARCHAR(255) NOT NULL,\n",
    "    SourceSystem VARCHAR(255) NOT NULL,\n",
    "    SourceId VARCHAR(255) NOT NULL,\n",
    "    CanonicalId VARCHAR(8) NOT NULL,\n",
    "    CreatedAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    PRIMARY KEY (OntologyType, SourceSystem, SourceId),\n",
    "    FOREIGN KEY (CanonicalId) REFERENCES canonical_ids(CanonicalId),\n",
    "    INDEX idx_canonical (CanonicalId)\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=latin1\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Schema created\")\n",
    "\n",
    "# Load sample data\n",
    "csv_path = '/Users/kennyr/workspace/docs/rfcs/XXX-stable_identifiers/identifiers_sample.csv'\n",
    "sample_data = []\n",
    "with open(csv_path, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        sample_data.append(row)\n",
    "\n",
    "# Insert canonical IDs first\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "for record in sample_data:\n",
    "    cursor.execute(\n",
    "        \"INSERT IGNORE INTO canonical_ids (CanonicalId, Status) VALUES (%s, 'assigned')\",\n",
    "        (record['CanonicalId'],)\n",
    "    )\n",
    "conn.commit()\n",
    "\n",
    "# Insert identifiers\n",
    "for record in sample_data:\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO identifiers (OntologyType, SourceSystem, SourceId, CanonicalId) VALUES (%s, %s, %s, %s)\",\n",
    "        (record['OntologyType'], record['SourceSystem'], record['SourceId'], record['CanonicalId'])\n",
    "    )\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"✓ Loaded {len(sample_data)} sample records\")\n",
    "\n",
    "# Pre-generate free IDs\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "generated = 0\n",
    "for _ in range(200):\n",
    "    new_id = generate_canonical_id()\n",
    "    cursor.execute(\n",
    "        \"INSERT IGNORE INTO canonical_ids (CanonicalId, Status) VALUES (%s, 'free')\",\n",
    "        (new_id,)\n",
    "    )\n",
    "    if cursor.rowcount > 0:\n",
    "        generated += 1\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"✓ Pre-generated {generated} free IDs\")\n",
    "\n",
    "# Show pool status\n",
    "result = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "print(\"\\nCanonical ID pool status:\")\n",
    "for row in result:\n",
    "    print(f\"  {row['Status']:10} {row['count']:5} IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911f305",
   "metadata": {},
   "source": [
    "## Initialize ID Minter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4800213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ID Minter initialized\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import id_minter\n",
    "importlib.reload(id_minter)\n",
    "from id_minter import IDMinter\n",
    "\n",
    "minter = IDMinter(get_connection)\n",
    "print(\"✓ ID Minter initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d4ba9",
   "metadata": {},
   "source": [
    "## 1. Batch Lookup\n",
    "\n",
    "The `lookup_ids()` method efficiently fetches canonical IDs for multiple source identifiers in a single query. This is the hot path - most records processed already have canonical IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d478d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Batch Lookup Demo\n",
      "============================================================\n",
      "\n",
      "Looking up 4 source IDs (mixed ontology types):\n",
      "  Work/sierra-system-number/1001768\n",
      "  Work/sierra-system-number/1007167\n",
      "  Image/sierra-system-number/1007828\n",
      "  Work/axiell-collections-id/DOES-NOT-EXIST\n",
      "\n",
      "Found 2 existing canonical IDs:\n",
      "  ✓ Work/sierra-system-number/1001768 -> nvkdnjxp\n",
      "  ✓ Work/sierra-system-number/1007167 -> swbrj79k\n",
      "\n",
      "Not found (would need minting): 2\n",
      "  ✗ Image/sierra-system-number/1007828\n",
      "  ✗ Work/axiell-collections-id/DOES-NOT-EXIST\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Batch Lookup Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get some existing IDs to lookup\n",
    "existing = execute_query(\"\"\"\n",
    "    SELECT OntologyType, SourceSystem, SourceId, CanonicalId \n",
    "    FROM identifiers \n",
    "    WHERE SourceSystem = 'sierra-system-number' AND OntologyType = 'Work'\n",
    "    LIMIT 3\n",
    "\"\"\", fetch=True)\n",
    "\n",
    "# Create test batch: mix of existing and non-existing, different ontology types\n",
    "test_batch = [\n",
    "    ('Work', 'sierra-system-number', existing[0]['SourceId']),      # Exists\n",
    "    ('Work', 'sierra-system-number', existing[1]['SourceId']),      # Exists\n",
    "    ('Image', 'sierra-system-number', existing[2]['SourceId']),     # Different ontology (won't exist)\n",
    "    ('Work', 'axiell-collections-id', 'DOES-NOT-EXIST'),           # Non-existent\n",
    "]\n",
    "\n",
    "print(f\"\\nLooking up {len(test_batch)} source IDs (mixed ontology types):\")\n",
    "for ont, sys, sid in test_batch:\n",
    "    print(f\"  {ont}/{sys}/{sid}\")\n",
    "\n",
    "found = minter.lookup_ids(test_batch)\n",
    "\n",
    "print(f\"\\nFound {len(found)} existing canonical IDs:\")\n",
    "for (ont, sys, sid), cid in found.items():\n",
    "    print(f\"  ✓ {ont}/{sys}/{sid} -> {cid}\")\n",
    "\n",
    "missing = [sid for sid in test_batch if sid not in found]\n",
    "print(f\"\\nNot found (would need minting): {len(missing)}\")\n",
    "for ont, sys, sid in missing:\n",
    "    print(f\"  ✗ {ont}/{sys}/{sid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6561aad",
   "metadata": {},
   "source": [
    "## 2. Batch Minting\n",
    "\n",
    "The `mint_ids()` method combines batch lookup with minting in a single transaction (~6 queries regardless of batch size):\n",
    "\n",
    "1. Batch lookup source IDs + predecessor IDs\n",
    "2. Fail fast if any predecessors missing\n",
    "3. Batch INSERT for predecessor inheritance\n",
    "4. Claim free IDs from pool\n",
    "5. Batch INSERT for new IDs\n",
    "6. Verify and mark as assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658aa867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Batch Minting Demo\n",
      "============================================================\n",
      "\n",
      "Processing 4 requests:\n",
      "  1. Work/sierra-system-number/1001768\n",
      "  2. Work/sierra-system-number/1007167\n",
      "  3. Work/axiell-collections-id/AC-BATCH-312034 <- Work/sierra-system-number/1001768\n",
      "  4. Work/axiell-collections-id/AC-NEW-390046\n",
      "\n",
      "Results:\n",
      "  Work/sierra-system-number/1001768 -> nvkdnjxp (found)\n",
      "  Work/sierra-system-number/1007167 -> swbrj79k (found)\n",
      "  Work/axiell-collections-id/AC-BATCH-312034 -> nvkdnjxp (inherited ✓)\n",
      "  Work/axiell-collections-id/AC-NEW-390046 -> a5jxa52t (minted)\n",
      "\n",
      "Free IDs consumed: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Batch Minting Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get pool status before\n",
    "pool_before = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_before = next(r['count'] for r in pool_before if r['Status'] == 'free')\n",
    "\n",
    "# Get existing Sierra records for predecessor test\n",
    "existing_works = execute_query(\"\"\"\n",
    "    SELECT SourceId, CanonicalId FROM identifiers \n",
    "    WHERE SourceSystem = 'sierra-system-number' AND OntologyType = 'Work'\n",
    "    LIMIT 2\n",
    "\"\"\", fetch=True)\n",
    "\n",
    "# Create batch request with mix of:\n",
    "# - Existing IDs (should be found)\n",
    "# - New ID with predecessor (should inherit canonical ID)\n",
    "# - Brand new ID (should claim from pool)\n",
    "requests = [\n",
    "    (('Work', 'sierra-system-number', existing_works[0]['SourceId']), None),  # Exists\n",
    "    (('Work', 'sierra-system-number', existing_works[1]['SourceId']), None),  # Exists\n",
    "    (('Work', 'axiell-collections-id', f'AC-BATCH-{random.randint(100000, 999999)}'), \n",
    "     ('Work', 'sierra-system-number', existing_works[0]['SourceId'])),  # Inherits\n",
    "    (('Work', 'axiell-collections-id', f'AC-NEW-{random.randint(100000, 999999)}'), None),  # New\n",
    "]\n",
    "\n",
    "print(f\"\\nProcessing {len(requests)} requests:\")\n",
    "for i, (source_id, predecessor) in enumerate(requests):\n",
    "    ont, sys, sid = source_id\n",
    "    pred_str = f\" <- {predecessor[0]}/{predecessor[1]}/{predecessor[2]}\" if predecessor else \"\"\n",
    "    print(f\"  {i+1}. {ont}/{sys}/{sid}{pred_str}\")\n",
    "\n",
    "# Execute batch mint\n",
    "results = minter.mint_ids(requests)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "for (ont, sys, sid), cid in results.items():\n",
    "    # Determine status\n",
    "    was_existing = any(sys == 'sierra-system-number' and sid == w['SourceId'] for w in existing_works)\n",
    "    pred = next((r[1] for r in requests if r[0] == (ont, sys, sid) and r[1]), None)\n",
    "    \n",
    "    if was_existing:\n",
    "        status = \"found\"\n",
    "    elif pred:\n",
    "        expected = existing_works[0]['CanonicalId']\n",
    "        status = \"inherited ✓\" if cid == expected else \"inherited ✗\"\n",
    "    else:\n",
    "        status = \"minted\"\n",
    "    \n",
    "    print(f\"  {ont}/{sys}/{sid} -> {cid} ({status})\")\n",
    "\n",
    "# Check pool status after\n",
    "pool_after = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_after = next(r['count'] for r in pool_after if r['Status'] == 'free')\n",
    "\n",
    "print(f\"\\nFree IDs consumed: {free_before - free_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367b36c",
   "metadata": {},
   "source": [
    "## 3. Predecessor Inheritance\n",
    "\n",
    "When migrating from one source system to another (e.g., Sierra → Axiell Collections), new records can inherit the canonical ID of their predecessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6355b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Predecessor Inheritance Demo\n",
      "============================================================\n",
      "\n",
      "Existing Sierra Work records to migrate:\n",
      "  sierra-system-number/1026798 -> jw8huput\n",
      "  sierra-system-number/1029638 -> vkgj5qyd\n",
      "  sierra-system-number/1042410 -> f7dd5efv\n",
      "  sierra-system-number/1043931 -> h47ef5sr\n",
      "  sierra-system-number/1045864 -> daha9q32\n",
      "\n",
      "Migrating to Axiell Collections...\n",
      "\n",
      "  1. axiell-collections-id/AC-MIGRATE-150289\n",
      "     Predecessor: sierra-system-number/1026798\n",
      "     Canonical ID: jw8huput (✓ Inherited)\n",
      "\n",
      "  2. axiell-collections-id/AC-MIGRATE-954192\n",
      "     Predecessor: sierra-system-number/1029638\n",
      "     Canonical ID: vkgj5qyd (✓ Inherited)\n",
      "\n",
      "  3. axiell-collections-id/AC-MIGRATE-281948\n",
      "     Predecessor: sierra-system-number/1042410\n",
      "     Canonical ID: f7dd5efv (✓ Inherited)\n",
      "\n",
      "  4. axiell-collections-id/AC-MIGRATE-115277\n",
      "     Predecessor: sierra-system-number/1043931\n",
      "     Canonical ID: h47ef5sr (✓ Inherited)\n",
      "\n",
      "  5. axiell-collections-id/AC-MIGRATE-669765\n",
      "     Predecessor: sierra-system-number/1045864\n",
      "     Canonical ID: daha9q32 (✓ Inherited)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Predecessor Inheritance Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get Sierra records to migrate\n",
    "sierra_records = execute_query(\"\"\"\n",
    "    SELECT SourceId, CanonicalId FROM identifiers \n",
    "    WHERE SourceSystem = 'sierra-system-number' AND OntologyType = 'Work'\n",
    "    LIMIT 5 OFFSET 10\n",
    "\"\"\", fetch=True)\n",
    "\n",
    "print(\"\\nExisting Sierra Work records to migrate:\")\n",
    "for rec in sierra_records:\n",
    "    print(f\"  sierra-system-number/{rec['SourceId']} -> {rec['CanonicalId']}\")\n",
    "\n",
    "print(\"\\nMigrating to Axiell Collections...\\n\")\n",
    "\n",
    "for i, sierra_rec in enumerate(sierra_records):\n",
    "    axiell_id = f\"AC-MIGRATE-{random.randint(100000, 999999)}\"\n",
    "    source_key = ('Work', 'axiell-collections-id', axiell_id)\n",
    "    predecessor = ('Work', 'sierra-system-number', sierra_rec['SourceId'])\n",
    "    \n",
    "    results = minter.mint_ids([(source_key, predecessor)])\n",
    "    canonical_id = results[source_key]\n",
    "    \n",
    "    # Verify inheritance\n",
    "    inherited = canonical_id == sierra_rec['CanonicalId']\n",
    "    status = \"✓ Inherited\" if inherited else \"✗ Wrong ID!\"\n",
    "    \n",
    "    print(f\"  {i+1}. axiell-collections-id/{axiell_id}\")\n",
    "    print(f\"     Predecessor: sierra-system-number/{sierra_rec['SourceId']}\")\n",
    "    print(f\"     Canonical ID: {canonical_id} ({status})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9117280",
   "metadata": {},
   "source": [
    "## 4. New Record Minting\n",
    "\n",
    "Brand new records without predecessors claim IDs from the pre-generated pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a796403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "New Record Minting Demo\n",
      "============================================================\n",
      "\n",
      "Pool before: 199 free, 10001 assigned\n",
      "\n",
      "Minting 10 brand new records...\n",
      "\n",
      "  1. axiell-collections-id/AC-BRAND-NEW-984091 -> a8d7wbed\n",
      "  2. axiell-collections-id/AC-BRAND-NEW-401343 -> a8ndwxru\n",
      "  3. axiell-collections-id/AC-BRAND-NEW-231693 -> accgquf6\n",
      "  4. axiell-collections-id/AC-BRAND-NEW-933341 -> at67nn5b\n",
      "  5. axiell-collections-id/AC-BRAND-NEW-278528 -> awdb4wn3\n",
      "  6. axiell-collections-id/AC-BRAND-NEW-499480 -> b3db6wda\n",
      "  7. axiell-collections-id/AC-BRAND-NEW-513695 -> b4s9w353\n",
      "  8. axiell-collections-id/AC-BRAND-NEW-736050 -> b69ekxkh\n",
      "  9. axiell-collections-id/AC-BRAND-NEW-955302 -> b779f5vh\n",
      "  10. axiell-collections-id/AC-BRAND-NEW-322800 -> b8xvbqtx\n",
      "\n",
      "Pool after: 189 free, 10011 assigned\n",
      "Free IDs consumed: 10\n",
      "Assigned IDs added: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"New Record Minting Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get pool status before\n",
    "pool_before = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_before = next(r['count'] for r in pool_before if r['Status'] == 'free')\n",
    "assigned_before = next(r['count'] for r in pool_before if r['Status'] == 'assigned')\n",
    "\n",
    "print(f\"\\nPool before: {free_before} free, {assigned_before} assigned\")\n",
    "\n",
    "# Mint 10 brand new records (no predecessors) - using batch\n",
    "print(\"\\nMinting 10 brand new records...\\n\")\n",
    "\n",
    "requests = []\n",
    "for i in range(10):\n",
    "    axiell_id = f\"AC-BRAND-NEW-{random.randint(100000, 999999)}\"\n",
    "    source_key = ('Work', 'axiell-collections-id', axiell_id)\n",
    "    requests.append((source_key, None))\n",
    "\n",
    "results = minter.mint_ids(requests)\n",
    "\n",
    "for i, (source_key, _) in enumerate(requests):\n",
    "    ont, sys, sid = source_key\n",
    "    canonical_id = results[source_key]\n",
    "    print(f\"  {i+1}. {sys}/{sid} -> {canonical_id}\")\n",
    "\n",
    "# Get pool status after\n",
    "pool_after = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_after = next(r['count'] for r in pool_after if r['Status'] == 'free')\n",
    "assigned_after = next(r['count'] for r in pool_after if r['Status'] == 'assigned')\n",
    "\n",
    "print(f\"\\nPool after: {free_after} free, {assigned_after} assigned\")\n",
    "print(f\"Free IDs consumed: {free_before - free_after}\")\n",
    "print(f\"Assigned IDs added: {assigned_after - assigned_before}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646037a",
   "metadata": {},
   "source": [
    "## 5. Race Condition Protection\n",
    "\n",
    "The ID Minter uses `FOR UPDATE SKIP LOCKED` to handle concurrent access safely:\n",
    "\n",
    "- Multiple processes can claim different free IDs without blocking\n",
    "- If two processes try to mint the same source ID, one wins and the other's claimed ID stays free\n",
    "- Verification query detects which IDs were actually used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04bb9694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Race Condition Protection Demo\n",
      "============================================================\n",
      "\n",
      "Free IDs before test: 189\n",
      "\n",
      "--- Test 1: Same source ID, 5 concurrent threads ---\n",
      "Source ID: Work/race-test/RACE-TEST-1-998827\n",
      "\n",
      "Results from 5 threads:\n",
      "  Thread 0: bb68hbe7\n",
      "  Thread 1: bb68hbe7\n",
      "  Thread 2: bb68hbe7\n",
      "  Thread 3: bb68hbe7\n",
      "  Thread 4: bb68hbe7\n",
      "\n",
      "✓ All threads returned the same canonical ID: bb68hbe7\n",
      "\n",
      "Free IDs consumed: 1\n",
      "✓ Only 1 ID was claimed (unused IDs stayed in pool)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Race Condition Protection Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Track results from concurrent threads\n",
    "race_results = {}\n",
    "race_lock = threading.Lock()\n",
    "\n",
    "def mint_same_id(thread_id: int, source_id: str):\n",
    "    \"\"\"Each thread tries to mint the same source ID.\"\"\"\n",
    "    # Each thread gets its own minter with its own connection\n",
    "    thread_minter = IDMinter(get_connection)\n",
    "    try:\n",
    "        source_key = ('Work', 'race-test', source_id)\n",
    "        results = thread_minter.mint_ids([(source_key, None)])\n",
    "        canonical_id = results[source_key]\n",
    "        with race_lock:\n",
    "            race_results[thread_id] = canonical_id\n",
    "    finally:\n",
    "        thread_minter.close()\n",
    "\n",
    "# Get pool status before\n",
    "pool_before = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_before = next(r['count'] for r in pool_before if r['Status'] == 'free')\n",
    "\n",
    "print(f\"\\nFree IDs before test: {free_before}\")\n",
    "\n",
    "# Test 1: Multiple threads trying to mint the SAME source ID\n",
    "print(\"\\n--- Test 1: Same source ID, 5 concurrent threads ---\")\n",
    "test_source_id = f\"RACE-TEST-1-{random.randint(100000, 999999)}\"\n",
    "print(f\"Source ID: Work/race-test/{test_source_id}\")\n",
    "\n",
    "race_results.clear()\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=mint_same_id, args=(i, test_source_id))\n",
    "    threads.append(t)\n",
    "\n",
    "# Start all threads simultaneously\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"\\nResults from {len(race_results)} threads:\")\n",
    "for thread_id, cid in sorted(race_results.items()):\n",
    "    print(f\"  Thread {thread_id}: {cid}\")\n",
    "\n",
    "# All threads should return the same canonical ID\n",
    "unique_ids = set(race_results.values())\n",
    "if len(unique_ids) == 1:\n",
    "    print(f\"\\n✓ All threads returned the same canonical ID: {list(unique_ids)[0]}\")\n",
    "else:\n",
    "    print(f\"\\n✗ ERROR: Got different canonical IDs: {unique_ids}\")\n",
    "\n",
    "# Check that only 1 free ID was consumed (not 5)\n",
    "pool_after_test1 = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_after_test1 = next(r['count'] for r in pool_after_test1 if r['Status'] == 'free')\n",
    "ids_consumed = free_before - free_after_test1\n",
    "\n",
    "print(f\"\\nFree IDs consumed: {ids_consumed}\")\n",
    "if ids_consumed == 1:\n",
    "    print(\"✓ Only 1 ID was claimed (unused IDs stayed in pool)\")\n",
    "else:\n",
    "    print(f\"✗ Expected 1 ID consumed, got {ids_consumed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d400dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 2: Different source IDs, 10 concurrent threads ---\n",
      "\n",
      "Results from 10 threads:\n",
      "  Thread 0: c2ssxa2x\n",
      "  Thread 1: c6x5k57k\n",
      "  Thread 2: c22c8pst\n",
      "  Thread 3: c79j2uaa\n",
      "  Thread 4: bjh53qgd\n",
      "  Thread 5: c4vf6qqn\n",
      "  Thread 6: c6rfrkef\n",
      "  Thread 7: cbcewhwq\n",
      "  Thread 8: bkckaubc\n",
      "  Thread 9: bcbv5jzv\n",
      "\n",
      "✓ All 10 threads got unique canonical IDs\n",
      "Free IDs consumed: 10\n",
      "✓ Exactly 10 IDs claimed (one per thread)\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Multiple threads minting DIFFERENT source IDs\n",
    "print(\"\\n--- Test 2: Different source IDs, 10 concurrent threads ---\")\n",
    "\n",
    "pool_before_test2 = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_before_test2 = next(r['count'] for r in pool_before_test2 if r['Status'] == 'free')\n",
    "\n",
    "race_results.clear()\n",
    "threads = []\n",
    "for i in range(10):\n",
    "    unique_source_id = f\"RACE-TEST-2-{i}-{random.randint(100000, 999999)}\"\n",
    "    t = threading.Thread(target=mint_same_id, args=(i, unique_source_id))\n",
    "    threads.append(t)\n",
    "\n",
    "# Start all threads simultaneously\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"\\nResults from {len(race_results)} threads:\")\n",
    "for thread_id, cid in sorted(race_results.items()):\n",
    "    print(f\"  Thread {thread_id}: {cid}\")\n",
    "\n",
    "# All threads should have different canonical IDs\n",
    "unique_ids = set(race_results.values())\n",
    "if len(unique_ids) == 10:\n",
    "    print(f\"\\n✓ All 10 threads got unique canonical IDs\")\n",
    "else:\n",
    "    print(f\"\\n✗ Expected 10 unique IDs, got {len(unique_ids)}\")\n",
    "\n",
    "# Check that 10 free IDs were consumed\n",
    "pool_after_test2 = execute_query(\"SELECT Status, COUNT(*) as count FROM canonical_ids GROUP BY Status\", fetch=True)\n",
    "free_after_test2 = next(r['count'] for r in pool_after_test2 if r['Status'] == 'free')\n",
    "ids_consumed = free_before_test2 - free_after_test2\n",
    "\n",
    "print(f\"Free IDs consumed: {ids_consumed}\")\n",
    "if ids_consumed == 10:\n",
    "    print(\"✓ Exactly 10 IDs claimed (one per thread)\")\n",
    "else:\n",
    "    print(f\"  Expected 10, got {ids_consumed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a534063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 3: Idempotency ---\n",
      "Source ID: Work/idempotent-test/IDEMPOTENT-TEST-312071\n",
      "\n",
      "First mint:  cv7mybm7\n",
      "Second mint: cv7mybm7\n",
      "\n",
      "✓ Idempotent: same canonical ID returned\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Idempotency - minting the same ID twice returns the same result\n",
    "print(\"\\n--- Test 3: Idempotency ---\")\n",
    "\n",
    "test_source_id = f\"IDEMPOTENT-TEST-{random.randint(100000, 999999)}\"\n",
    "print(f\"Source ID: Work/idempotent-test/{test_source_id}\")\n",
    "\n",
    "source_key = ('Work', 'idempotent-test', test_source_id)\n",
    "\n",
    "# First mint\n",
    "results = minter.mint_ids([(source_key, None)])\n",
    "canonical_id_1 = results[source_key]\n",
    "print(f\"\\nFirst mint:  {canonical_id_1}\")\n",
    "\n",
    "# Second mint (same source ID)\n",
    "results = minter.mint_ids([(source_key, None)])\n",
    "canonical_id_2 = results[source_key]\n",
    "print(f\"Second mint: {canonical_id_2}\")\n",
    "\n",
    "if canonical_id_1 == canonical_id_2:\n",
    "    print(\"\\n✓ Idempotent: same canonical ID returned\")\n",
    "else:\n",
    "    print(\"\\n✗ ERROR: different canonical IDs returned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f72fd",
   "metadata": {},
   "source": [
    "## 6. Alias Discovery\n",
    "\n",
    "After migration, multiple source identifiers may share the same canonical ID. The `CreatedAt` timestamp indicates which was the original and which are aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79f7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Alias Discovery Demo\n",
      "============================================================\n",
      "\n",
      "Found 5 canonical IDs with multiple source identifiers:\n",
      "\n",
      "Canonical ID: daha9q32\n",
      "--------------------------------------------------\n",
      "  [Original] sierra-system-number/1045864\n",
      "           Created: 2026-02-09 11:57:52\n",
      "  [Alias   ] axiell-collections-id/AC-MIGRATE-669765\n",
      "           Created: 2026-02-09 11:58:08\n",
      "\n",
      "Canonical ID: f7dd5efv\n",
      "--------------------------------------------------\n",
      "  [Original] sierra-system-number/1042410\n",
      "           Created: 2026-02-09 11:57:53\n",
      "  [Alias   ] axiell-collections-id/AC-MIGRATE-281948\n",
      "           Created: 2026-02-09 11:58:08\n",
      "\n",
      "Canonical ID: h47ef5sr\n",
      "--------------------------------------------------\n",
      "  [Original] sierra-system-number/1043931\n",
      "           Created: 2026-02-09 11:57:53\n",
      "  [Alias   ] axiell-collections-id/AC-MIGRATE-115277\n",
      "           Created: 2026-02-09 11:58:08\n",
      "\n",
      "Canonical ID: jw8huput\n",
      "--------------------------------------------------\n",
      "  [Original] sierra-system-number/1026798\n",
      "           Created: 2026-02-09 11:57:52\n",
      "  [Alias   ] axiell-collections-id/AC-MIGRATE-150289\n",
      "           Created: 2026-02-09 11:58:08\n",
      "\n",
      "Canonical ID: nvkdnjxp\n",
      "--------------------------------------------------\n",
      "  [Original] sierra-system-number/1001768\n",
      "           Created: 2026-02-09 11:57:52\n",
      "  [Alias   ] axiell-collections-id/AC-BATCH-312034\n",
      "           Created: 2026-02-09 11:58:05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Alias Discovery Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find canonical IDs with multiple source identifiers\n",
    "aliased = execute_query(\"\"\"\n",
    "    SELECT CanonicalId, COUNT(*) as count\n",
    "    FROM identifiers \n",
    "    GROUP BY CanonicalId \n",
    "    HAVING COUNT(*) > 1\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 5\n",
    "\"\"\", fetch=True)\n",
    "\n",
    "print(f\"\\nFound {len(aliased)} canonical IDs with multiple source identifiers:\\n\")\n",
    "\n",
    "for item in aliased:\n",
    "    canonical_id = item['CanonicalId']\n",
    "    \n",
    "    # Get all source identifiers with alias status\n",
    "    details = execute_query(\"\"\"\n",
    "        SELECT \n",
    "            i.*,\n",
    "            CASE WHEN i.CreatedAt = earliest.MinCreatedAt THEN 'Original' ELSE 'Alias' END AS Status\n",
    "        FROM identifiers i\n",
    "        JOIN (\n",
    "            SELECT CanonicalId, MIN(CreatedAt) AS MinCreatedAt \n",
    "            FROM identifiers \n",
    "            GROUP BY CanonicalId\n",
    "        ) earliest ON i.CanonicalId = earliest.CanonicalId\n",
    "        WHERE i.CanonicalId = %s\n",
    "        ORDER BY i.CreatedAt\n",
    "    \"\"\", (canonical_id,), fetch=True)\n",
    "    \n",
    "    print(f\"Canonical ID: {canonical_id}\")\n",
    "    print(\"-\" * 50)\n",
    "    for d in details:\n",
    "        print(f\"  [{d['Status']:8}] {d['SourceSystem']}/{d['SourceId']}\")\n",
    "        print(f\"           Created: {d['CreatedAt']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce26e7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Batch lookup** - Single query for multiple source IDs with mixed ontology types\n",
    "2. **Batch minting** - Combined lookup + mint in ~6 queries regardless of batch size\n",
    "3. **Predecessor inheritance** - Migrated records inherit canonical IDs from old systems\n",
    "4. **New record minting** - Claims from pre-generated pool\n",
    "5. **Race condition protection**:\n",
    "   - Same source ID: All threads get same canonical ID, only 1 pool ID consumed\n",
    "   - Different source IDs: Each thread gets unique ID, no blocking\n",
    "   - Idempotency: Repeated mints return same result\n",
    "6. **Alias discovery** - Identify original vs. alias by `CreatedAt` timestamp\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "| Property | Behavior |\n",
    "|----------|----------|\n",
    "| Concurrency | `FOR UPDATE SKIP LOCKED` - no blocking |\n",
    "| Race detection | Verification query after INSERT |\n",
    "| ID pool | Unused IDs stay free (not wasted) |\n",
    "| Idempotency | Same source ID always returns same canonical ID |\n",
    "| Atomicity | All operations in single transaction |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe2323",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Run this to stop and remove the Docker container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f3f1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Minter connection closed\n",
      "\u001b[?25l\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠋\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠙\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠹\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.3s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠸\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.4s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠼\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.5s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠴\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.6s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠦\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.7s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠧\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.8s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠇\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m0.9s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠏\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m1.0s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠋\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m1.1s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 0/1\n",
      " \u001b[33m⠙\u001b[0m Container id-minter-mysql Stopping                                      \u001b[34m1.2s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[2A\u001b[0G[+] down 2/3\n",
      " \u001b[32m✔\u001b[0m Container id-minter-mysql                \u001b[32mRemoved\u001b[0m                        \u001b[34m1.3s \u001b[0m\n",
      " \u001b[33m⠋\u001b[0m Network xxx-stable_identifiers_default   Removing                       \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Volume xxx-stable_identifiers_mysql_data \u001b[32mRemoved\u001b[0m                        \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[4A\u001b[0G[+] down 2/3\n",
      " \u001b[32m✔\u001b[0m Container id-minter-mysql                \u001b[32mRemoved\u001b[0m                        \u001b[34m1.3s \u001b[0m\n",
      " \u001b[33m⠙\u001b[0m Network xxx-stable_identifiers_default   Removing                       \u001b[34m0.1s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Volume xxx-stable_identifiers_mysql_data \u001b[32mRemoved\u001b[0m                        \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h\u001b[?25l\u001b[4A\u001b[0G[+] down 3/3\n",
      " \u001b[32m✔\u001b[0m Container id-minter-mysql                \u001b[32mRemoved\u001b[0m                        \u001b[34m1.3s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Network xxx-stable_identifiers_default   \u001b[32mRemoved\u001b[0m                        \u001b[34m0.1s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Volume xxx-stable_identifiers_mysql_data \u001b[32mRemoved\u001b[0m                        \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h✓ Docker container stopped\n"
     ]
    }
   ],
   "source": [
    "# Close connections\n",
    "if 'minter' in dir() and minter.conn and minter.conn.open:\n",
    "    minter.conn.close()\n",
    "    print(\"✓ Minter connection closed\")\n",
    "\n",
    "# Stop the container\n",
    "!docker compose down -v\n",
    "print(\"✓ Docker container stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-identifiers-rfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
